# RustTTS Performance Optimization Plan

**Status:** –í —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ  
**Start Date:** 2026-01-27  
**Target:** Dogon and exceed Python SDK performance

## Problem Analysis

T–µ–∫—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ—Å–ø–æ—Å–æ–±–Ω—ã:

| –ú–µ—Ç—Ä–∏–∫–∞ | Python (MPS GPU) | Rust (CPU) | Rust (Metal) | –ü–æ–±–µ–¥–∏—Ç–µ–ª—å |
|---------|------------------|-----------|--------------|------------|
| Short RTF | 2.59x | 4.24x | 4.24x | Python ‚≠ê |
| Medium RTF | 2.29x | 2.81x | 2.81x | Python ‚≠ê |
| Long RTF | 1.95x | 3.33x | 3.33x | Python ‚≠ê |
| Cold start | ~8s | ~1.3s | ~3.5s | Rust ‚≠ê |
| Size | ~2GB | ~12MB | ~12MB | Rust ‚≠ê |
| RAM | ~2GB | ~1.5GB | ~1.5GB | Rust ‚≠ê |

### Root Causes

1. **–ù–µ–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π Metal backend** - kernel launch overhead –Ω–∞ –∫–∞–∂–¥–æ–º —Ç–æ–∫–µ–Ω–µ
2. **–ù–ï–¢ Quantization** - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç f32 (–≤ 4x –º–µ–¥–ª–µ–Ω–Ω–µ–µ INT8)
3. **–ù–ï–¢ SIMD –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π** - generic kernels –≤–º–µ—Å—Ç–æ ARM NEON
4. **Architecture** - layer-by-layer –≤–º–µ—Å—Ç–æ fused kernels

## Optimization Phases

### Phase 1: Metal Backend Fix (1-2 weeks) üö® –°–†–û–ß–ù–û

#### 1.1 Profiler Integration
**–¶–µ–ª—å:** –ù–∞–π—Ç–∏ bottleneck –æ–ø–µ—Ä–∞—Ü–∏–∏

```rust
// crates/runtime/src/profiler.rs
use tracing::{info, instrument};

#[instrument(skip(audio))]
pub fn profile_section(name: &str) -> impl Drop {
    let start = Instant::now();
    info!("Section {} started", name);
    
    struct ProfilerGuard {
        name: String,
        start: Instant,
    }
    
    impl Drop for ProfilerGuard {
        fn drop(&mut self) {
            let elapsed = self.start.elapsed();
            info!("{} elapsed: {:?}", self.name, elapsed);
        }
    }
    
    ProfilerGuard { name: name.into(), start }
}
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```rust
pub fn synthesize(...) -> Result {
    let _p = profile_section("normalization");
    // ... 
    
    let _p = profile_section("tokenization");  
    // ...
}
```

#### 1.2 Metal Kernel Optimization

**–ü—Ä–æ–±–ª–µ–º—ã:**
- –û—Ç–¥–µ–ª—å–Ω—ã–π kernel –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ autoregressive  
- –ù–ï–¢ Fused Attention
- Generic kernels –≤–º–µ—Å—Ç–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö

**–†–µ—à–µ–Ω–∏—è:**

**Option A: Fused Attention Kernel**
```cuda
// Metal shader
kernel void fused_attention(
    const device float* q,
    const device float* k,
    const device float* v,
    const device int* cache,
    device float* out,
    const uint seq_len
) {
    // –í—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ attention –≤ –æ–¥–Ω–æ–º –≤—ã–∑–æ–≤–µ
    // min memory transfers
}
```

**Option B: Batch Generation**
```rust
// –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å 2-4 —Ç–æ–∫–µ–Ω–∞ –∑–∞ —Ä–∞–∑ –≥–¥–µ –≤–æ–∑–º–æ–∂–Ω–æ
// –£–º–µ–Ω—å—à–∏—Ç—å kernel launches –≤ 2-4x
const BATCH_SIZE: usize = 4;
```

**Option C: Shader Caching**
```rust
// crates/runtime/src/metal_cache.rs
use std::collections::HashMap;
use std::sync::{Mutex, Arc};

struct ShaderCache {
    cache: Mutex<HashMap<String, CompiledMetalLibrary>>,
    
    fn get_or_compile(&self, source: &str) -> Result<CompiledMetalLibrary> {
        let mut cache = self.cache.lock().unwrap();
        
        if let Some(shader) = cache.get(source) {
            return Ok(shader.clone());
        }
        
        let compiled = self.compile_shader(source)?;
        cache.insert(source.into(), compiled.clone());
        Ok(compiled)
    }
}
```

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:** RTF 4.24x ‚Üí 3.0x (~30% faster)

### Phase 2: Quantization (2-3 weeks) ‚≠ê‚≠ê‚≠ê –¢–û–ü –ü–†–ò–û–†–ò–¢–ï–¢

#### 2.1 INT8 Weights Storage
```toml
[dependencies]
candle-core = { version = "0.8", features = ["quantize"] }
candle-metal = { version = "0.8", features = ["int8"] }
```

```
–†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏:
- f32: 2.5 GB
- INT8: ~700 MB (3.5x –º–µ–Ω—å—à–µ!)
- INT4: ~350 MB (7x –º–µ–Ω—å—à–µ!)
```

#### 2.2 INT8 MatMul Kernels

```rust
// Quantized matrix multiplication
pub fn matmul_int8_quantized(a: &[i8], b: &[i8], scale_a: f32, scale_b: f32) -> Vec<f32> {
    use std::arch::aarch64::vld1q_s8;
    use std::arch::aarch64::vdotq_s32;
    
    // SIMD optimized I8 matmul
    unsafe {
        for i in (0..n).step_by(16) {
            let va = vld1q_s8(a.as_ptr().offset(i));
            let vb = vld1q_s8(b.as_ptr().offset(i));
            let result = vdotq_s32(...);
            // ...
        }
    }
}
```

#### 2.3 INT8 Attention Ops

```rust
// Quantized self-attention
pub fn attention_int8(
    q: &[i8], k: &[i8], v: &[i8],
    scale_qk: f32, scale_v: f32
) -> Vec<f32> {
    // –°–Ω–∞—á–∞–ª–∞ –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å INT8 dot product
    let scores = matmul_int8(q, k, scale_qk, 1.0);
    // –ó–∞—Ç–µ–º softmax + v matmul –≤ INT8
    // –¢–æ–ª—å–∫–æ –Ω–∞ –∫–æ–Ω—Ü–∞—Ö –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ f32
}
```

**–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:**

| Backend | f32 —Å–µ–π—á–∞—Å | INT8 | INT4 |
|---------|-----------|------|------|
| CPU | 4.24x RTF | **2.5x RTF** | **2.0x RTF** |
| Metal | 4.24x RTF | **2.5x RTF** | **2.0x RTF** |
| vs Python | ‚ùå –ø—Ä–æ–∏–≥—Ä—ã–≤–∞–µ—Ç | ‚úÖ –¥–æ–≥–Ω–∞–ª! | ‚úÖ –Ω–∞ 30% –±—ã—Å—Ç—Ä–µ–µ! |

### Phase 3: SIMD Optimization (CPU) (2 weeks)

#### 3.1 ARM NEON for Apple Silicon

```rust
// crates/acoustic-model/src/ops/neon.rs
#![cfg(target_arch = "aarch64")]
#![feature(stdsimd)]

use std::arch::aarch64::*;

pub unsafe fn neon_matmul_f32x4(
    a: &[f32], b: &[f32], out: &mut [f32]
) {
    for i in (0..256).step_by(4) {
        let a_vec = vld1q_f32(a.as_ptr().offset(i));
        let b_vec = vld1q_f32(b.as_ptr().offset(i));
        let result = vaddq_f32(a_vec, b_vec);
        vst1q_f32(out.as_mut_ptr().offset(i), result);
    }
}
```

#### 3.2 AVX512 for x86

```rust
// –î–ª—è Linux servers
#[cfg(target_arch = "x86_64")]
use std::arch::x86_64::*;

pub unsafe fn avx512_matmul(...) { /* ... */ }
```

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:** 15-25% —É—Å–∫–æ—Ä–µ–Ω–∏–µ –Ω–∞ CPU

### Phase 4: Architecture Optimizations (1-2 weeks)

#### 4.1 Fused Layer Kernels

**–°–µ–π—á–∞—Å:**
```rust
for layer in &model.layers {
    output = layer.attention(output, &mut cache)?;
    output = layer.mlp(output)?;
}
```

**Fused:**
```rust
// –û–¥–∏–Ω kernel –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–ª–æ—ë–≤
output = model.fused_layers_1_2(output, &mut cache)?;
```

#### 4.2 KV Cache Ring Buffer

```rust
// crates/runtime/src/cache/ring.rs
pub struct RingBufferCache<T> {
    data: Vec<T>,
    head: usize,  // Newest
    tail: usize,  // Oldest
    capacity: usize,
}

impl<T: Clone> RingBufferCache<T> {
    const EVICT: usize = 64; // Batch eviction
    
    pub fn push(&mut self, item: T) {
        self.data[self.head] = item;
        self.head = (self.head + 1) % self.capacity;
        
        if self.head == self.tail {
            self.tail = (self.tail + Self::EVICT) % self.capacity;
        }
    }
    
    // Minimize allocations –Ω–∞ 50%+
}
```

#### 4.3 Lazy Loading

```rust
// crates/runtime/src/loader.rs
pub struct LazyModelLoader {
    path: PathBuf,
    loaded: AtomicBool,
    model: OnceCell<Model>,
}

impl LazyModelLoader {
    pub fn get(&self) -> Result<&Model> {
        self.model.get_or_try_init(|| {
            Model::load(self.path)
        })
    }
}
```

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:** 10-20% —É—Å–∫–æ—Ä–µ–Ω–∏–µ

### Phase 5: Real-World Metrics (1 week)

RTF –Ω–µ –≥–ª–∞–≤–Ω–æ–µ –¥–ª—è TTS! –í–∞–∂–Ω–æ:

#### 5.1 Time-to-First-Audio (TTFA)
```
–¶–µ–ª—å: < 100ms –æ—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ –∞—É–¥–∏–æ

–ú–µ—Ç–æ–¥–∏–∫–∞:
- –û—Ç–º–µ—Ç–∏—Ç—å t‚ÇÄ = request received
- –û—Ç–º–µ—Ç–∏—Ç—å t‚ÇÅ = first audio chunk ready => TTFA = t‚ÇÅ - t‚ÇÄ
- Python: ~500ms (—Ç—Ä–µ–±—É–µ—Ç –≤—Å—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–∏—Ç—å)
- Rust —Ü–µ–ª—å: <100ms (streaming!)
```

#### 5.2 Streaming Throughput
```rust
// chunks –∫–∞–∂–¥—ã–µ 20-50ms –≤–æ –≤—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
// –Ω–µ –¥–æ–∂–∏–¥–∞—Ç—å—Å—è –ø–æ–ª–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–∫–∞–∫ –¥–µ–ª–∞–µ—Ç Python)
pub fn generate_streaming(text: &str) -> impl Stream<Item = AudioChunk> {
    // Stream generator yields —Å—Ä–∞–∑—É –∫–∞–∫ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ
    let mut pos = 0;
    loop {
        let chunk = generate_next_chunk(&text[pos..pos + CHUNK_SIZE])?;
        pos += chunk.duration;
        if pos >= text.len() { break; }
        yield chunk;
    }
}
```

#### 5.3 Memory Footprint
```rust
// Peak memory tracking
use tracing::{info, instrument};

#[instrument(skip(sample_rate, data))]
pub fn memory_tracking(sample_rate: usize, data: &[f32]) {
    let bytes = data.len() * mem::size_of::<f32>();
    info!("Memory: {} MB", bytes / (1024 * 1024));
}
```

#### 5.4 Latency Distribution
```
P50: <100ms
P90: <150ms  
P95: <200ms
P99: <300ms

Python: P99 ~800ms (–∏–Ω–æ–≥–¥–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏—Å–Ω–µ—Ç)
Rust —Ü–µ–ª—å: P99 <300ms (–¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ!)
```

## Quick Wins (2-3 days implementation)

### Win 1: Integrated Profiler (Day 1)

**—Ñ–∞–π–ª:** `crates/runtime/src/profiler.rs`

```rust
// crates/runtime/src/profiler.rs
use std::time::Instant;
use tracing::{info, warn};

#[derive(Default)]
pub struct Profiler {
    sections: Vec<(&'static str, Duration)>,
}

impl Profiler {
    pub fn section<'a>(&'a mut self, name: &'static str) -> ProfilerGuard<'a> {
        ProfilerGuard { name, start: Instant::now(), profiler: self }
    }
    
    pub fn summary(&self) {
        let total: Duration = self.sections.iter().map(|(_, d)| *d).sum();
        info!("=== PROFILER SUMMARY ===");
        info!("Total: {:?}", total);
        for (name, duration) in &self.sections {
            let pct = *duration as f64 / total.as_secs_f64() * 100.0;
            info!("{:20} {:8.2?} ({:5.1}%)", name, duration, pct);
            if pct > 30.0 {
                warn!("  ‚ö†Ô∏è  BOTTLENECK DETECTED!");
            }
        }
    }
}

pub struct ProfilerGuard<'a> {
    name: &'static str,
    start: Instant,
    profiler: &'a mut Profiler,
}

impl<'a> Drop for ProfilerGuard<'a> {
    fn drop(&mut self) {
        let duration = self.start.elapsed();
        self.profiler.sections.push((self.name, duration));
    }
}
```

**–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ pipeline:**

```rust
// crates/runtime/src/pipeline.rs
use crate::profiler::Profiler;

pub struct TtsPipeline {
    profiler: Profiler,
    // ...
}

impl TtsPipeline {
    pub fn synthesize(&mut self, text: &str) -> Result<Vec<f32>> {
        let mut profiler = Profiler::default();
        
        {
            let _p = profiler.section("normalization");
            self.normalize(text)?;
        }
        
        {
            let _p = profiler.section("tokenization");
            let tokens = self.tokenize(text)?;
        }
        
        {
            let _p = profiler.section("model_forward");
            let codes = self.model.forward(&tokens)?;
        }
        
        {
            let _p = profiler.section("codec_decode");
            let audio = self.codec.decode(&codes)?;
        }
        
        profiler.summary();
        Ok(audio)
    }
}
```

### Win 2: Reduce Allocations (Day 1-2)

**–§–∞–π–ª:** `crates/audio-codec-12hz/src/allocator.rs`

```rust
use std::sync::Mutex;
use std::collections::VecDeque;

pub struct ReusableBuffer<T> {
    buffers: Mutex<VecDeque<Vec<T>>>,
    capacity: usize,
}

impl<T: Clone> ReusableBuffer<T> {
    pub fn with_capacity(capacity: usize) -> Self {
        Self {
            buffers: Mutex::new(VecDeque::with_capacity(4)),
            capacity,
        }
    }
    
    pub fn get(&self) -> Vec<T> {
        let mut buffers = self.buffers.lock().unwrap();
        if let Some(mut buf) = buffers.pop_back() {
            buf.clear();
            buf
        } else {
            Vec::with_capacity(self.capacity)
        }
    }
    
    pub fn return_buffer(&self, mut buffer: Vec<T>) {
        let mut buffers = self.buffers.lock().unwrap();
        if buffers.len() < 4 {
            buffer.clear();
            buffers.push_back(buffer);
        }
    }
}

// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
let mut buffer = reusable.get();
// ... —Ä–∞–±–æ—Ç–∞ —Å buffer ...
reusable.return_buffer(buffer);
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- –£–º–µ–Ω—å—à–∏—Ç—å GC pressure –Ω–∞ 50%+
- –ë–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π latency

### Win 3: Metal Shader Caching (Day 2)

**–§–∞–π–ª:** `crates/runtime/src/metal_cache.rs`

```rust
use candle_core::{Device, Result as CandleResult};
use candle_metal::MetalDevice;
use std::collections::HashMap;
use std::sync::{Arc, Mutex};
use std::path::PathBuf;

pub struct MetalShaderRegistry {
    shaders: Mutex<HashMap<String, CachedShader>>,
    cache_dir: PathBuf,
}

struct CachedShader {
    library: Arc<CompiledMetalLibrary>,
    compiled_at: std::time::SystemTime,
}

impl MetalShaderRegistry {
    pub fn new() -> Self {
        let cache_dir = std::env::var("XDG_CACHE_HOME")
            .map(PathBuf::from)
            .unwrap_or_else(|_| PathBuf::from(".cache/rusttts-metal"));
        
        std::fs::create_dir_all(&cache_dir).ok();
        
        Self {
            shaders: Mutex::new(HashMap::new()),
            cache_dir,
        }
    }
    
    pub fn get_or_compile(&self, source: &str, name: &str) -> Result<Arc<CompiledMetalLibrary>> {
        // Check cache
        {
            let shaders = self.shaders.lock().unwrap();
            if let Some(cached) = shaders.get(name) {
                // Check age (< 1 week = use cached)
                let age = cached.compiled_at.elapsed().unwrap().as_secs();
                if age < 604800 {  // 7 days
                    return Ok(cached.library.clone());
                }
            }
        }
        
        // Compile new shader
        let device = self.device();
        let lib = device.compile_shader(source)?;
        
        // Cache to disk
        let cache_file = self.cache_dir.join(format!("{}.bincache", name));
        bincode::serialize_into(
            &std::fs::File::create(cache_file)?,
            &lib.serialize()?
        )?;
        
        // Store in memory cache
        let cached = CachedShader {
            library: Arc::new(lib),
            compiled_at: std::time::SystemTime::now(),
        };
        
        let mut shaders = self.shaders.lock().unwrap();
        shaders.insert(name.into(), cached);
        
        Ok(cached.library)
    }
}
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- –£–±—Ä–∞—Ç—å compile overhead –Ω–∞ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ
- Faster subsequent runs (cold start: 1.3s ‚Üí 0.3s)

### Win 4: Pre-Warm Models (Day 2-3)

**–§–∞–π–ª:** `crates/runtime/src/warm.rs`

```rust
pub use candle_core::Result;

pub async fn warm_model_cache(model: &Model, sample_text: &str) -> Result<()> {
    info!("Warming cache with sample synthesis...");
    
    // 5 warmup runs
    for i in 0..5 {
        info!("Warmup run {}/5", i + 1);
        model.synthesize(sample_text)?;
    }
    
    info!("Cold start pre-warming complete");
    Ok(())
}
```

**–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –ø—Ä–∏ service startup:**

```rust
// crates/tts-server/src/main.rs
#[tokio::main]
async fn main() -> Result<()> {
    let model = Model::load(...)?;
    
    // Warm on startup
    warm_model_cache(&model, "–¢–µ–∫—Å—Ç –ø—Ä–∏–º–µ—Ä –¥–ª—è –ø—Ä–æ–≥—Ä–µ–≤–∞.")?;
    
    // Start server
    start_server(model).await?;
}
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- –ü–µ—Ä–≤—ã–π user request –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –±—ã—Å—Ç—Ä–æ
- Model JIT compilation –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø—Ä–∏ startup, –Ω–µ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º request

### Win 5: Tracing Integration (Day 3)

**–§–∞–π–ª:** `crates/runtime/src/tracing_setup.rs`

```rust
use tracing_subscriber::{filter, fmt, EnvFilter};

pub fn init_tracing() {
    tracing_subscriber::fmt()
        .compact()
        .with_max_level(tracing::Level::INFO)
        .with_env_filter(
            EnvFilter::from_default_env()
                .add_directive("rusttts=debug".parse().unwrap())
        )
        .init();
}
```

**–í main.rs:**
```rust
#[tokio::main] 
async fn main() {
    runtime::tracing_setup::init_tracing();
    // ...
}
```

## Implementation Timeline

| Week | Tasks | Target |
|------|-------|--------|
| **Week 1** | Profiler, Allocations, Metal Cache, Tracing | –ë—ã—Å—Ç—Ä—ã–µ wins –∑–∞–≤–µ—Ä—à–µ–Ω—ã |
| **Week 2** | Metal kernel optimization + SIMD | Metal RTF –ø–æ–¥ 3.5x, CPU 3.5x |
| **Week 3-4** | INT8 Quantization | RTF –ø–æ–¥ 2.5x (–¥–æ–≥–Ω–∞—Ç—å/–ø—Ä–µ–≤–∑–æ–π—Ç–∏ Python!) |
| **Week 5** | Fused kernels + Ring buffer cache | –ï—â—ë 20% —É—Å–∫–æ—Ä–µ–Ω–∏–µ |
| **Week 6** | Real metrics (TTFA, streaming) | Production-ready |

## Success Criteria

| Metric | –°–µ–π—á–∞—Å | Target | Status |
|--------|--------|--------|--------|
| Metal RTF (short) | 4.24x | < 3.0x | ‚ùå |
| CPU RTF (medium) | 2.81x | < 2.5x | ‚ö†Ô∏è |
| Time-to-first-audio | ??? | < 100ms | ‚ùå |
| Cold start | 1.3s | < 0.5s | ‚ö†Ô∏è |
| Memory (peak) | 1.5GB | < 700MB | ‚ùå |
| Binary size | 12MB | < 10MB | ‚ö†Ô∏è |

## Notes

### –ó–∞–º–µ—Ä—ã (tts-cli synth, real time)

| –ú–æ–¥–µ–ª—å | –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ | –í—Ä–µ–º—è (—Å–µ–∫) | –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ |
|--------|------------|-------------|------------|
| Q4 GGUF | CPU | 14.66 | –ü–æ–ª–Ω—ã–π –ø—Ä–æ–≥–æ–Ω (–≤–∫–ª—é—á–∞—è –∑–∞–≥—Ä—É–∑–∫—É) |
| Q8 GGUF | CPU | 10.28 | –ü–æ–ª–Ω—ã–π –ø—Ä–æ–≥–æ–Ω (–≤–∫–ª—é—á–∞—è –∑–∞–≥—Ä—É–∑–∫—É) |
| Q4 GGUF | Metal | 16.81 | –ü–æ–ª–Ω—ã–π –ø—Ä–æ–≥–æ–Ω (–≤–∫–ª—é—á–∞—è –∑–∞–≥—Ä—É–∑–∫—É) |
| Q8 GGUF | Metal | 10.12 | –ü–æ–ª–Ω—ã–π –ø—Ä–æ–≥–æ–Ω (–≤–∫–ª—é—á–∞—è –∑–∞–≥—Ä—É–∑–∫—É) |

- **–ù–µ —Å—Ä–∞—Ç—å—Å—è —Å CPU vs GPU**: –µ—Å–ª–∏ –µ—Å—Ç—å GPU - –∏—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ!
- **Quantization –¥–∞—Å—Ç –Ω–∞–∏–±–æ–ª—å—à–∏–π –ø—Ä–∏—Ä–æ—Å—Ç**: INT8 2.5x –±—ã—Å—Ç—Ä–µ–µ f32
- **Metal kernel optimization –≤–∞–∂–µ–Ω –¥–ª—è Apple Silicon**: 30%+ —É—Å–∫–æ—Ä–µ–Ω–∏–µ
- **Architecture –æ–ø—Ç–∏–ºisations (fused kernels)**: –ª—ë–≥–∫–∏–µ wins 10-20%
- **–†–µ–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏**: RTF ‚â† latency streaming. TTFA + throughput –≤–∞–∂–Ω–µ–µ!

## Resources

- Candle quantization docs: https://huggingface.co/docs/candle/main/guides/quantization
- Metal Performance Shaders: https://apple.github.io/metal-shading-language/
- ARM NEON intrinsics: https://developer.arm.com/architecture/instruction-sets/intrinsics
- FFlash for Metal: https://github.com/microsoft/Flash-Attention