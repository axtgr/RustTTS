# План оптимизации KV Cache

## Цель
Уменьшить накладные расходы на копирование памяти при работе с KV Cache во время авторегрессионной генерации. Текущая реализация использует конкатенацию (`Tensor::cat`) на каждом шаге, что приводит к квадратичной сложности $O(L^2)$ по копированию памяти. Цель — перейти к линейной сложности $O(L)$ (или константной $O(1)$ на шаг).

## Текущая проблема
В `crates/acoustic-model/src/layers.rs`:
```rust
let k = Tensor::cat(&[cached_k, &k], 2)?;
let v = Tensor::cat(&[cached_v, &v], 2)?;
```
При генерации токена $N$, мы копируем все предыдущие $N-1$ токенов в новый буфер.

## План действий

### 1. Создание Baseline-бенчмарка
*   Создать `benches/kv_cache_bench.rs`.
*   Сценарий: эмуляция работы KV Cache в цикле генерации (например, 1000 шагов).
*   Метрики: время выполнения, пропускная способность.

### 2. Проектирование `FastKvCache`
*   Разработать структуру, владеющую пре-аллоцированным тензором.
*   Использовать `slice_assign` (или низкоуровневые API `candle`) для обновления данных in-place без переаллокаций.
*   Поддержка `view` для получения актуального среза данных.

Структура:
```rust
pub struct FastKvCache {
    k: Tensor, // [batch, heads, max_capacity, head_dim]
    v: Tensor,
    current_len: usize,
}
```

### 3. Интеграция в `acoustic-model`
*   **Layers (`layers.rs`):** Модифицировать `Attention::forward` и `TransformerBlock::forward` для приема `&mut FastKvCache`.
*   **Model (`model.rs`):**
    *   В `generate_from_embeds` инициализировать кэш полной длины.
    *   Переписать цикл генерации.

### 4. Оптимизация под Candle
*   Исследование API `candle-core` для эффективной вставки (scatter/slice_assign).
*   Убедиться в эффективности на CPU (Metal/CUDA в будущем).

### 5. Верификация
*   Сравнение результатов бенчмарков.
*   Проверка корректности генерации (тесты).
